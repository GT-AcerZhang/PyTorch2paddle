{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from Joe_nn_transfer import transfer, util, p2f_trans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Simply define your PyTorch model like usual, and create an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "pytorch_network = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Determine the names of the layers.\n",
    "\n",
    "For the above model example it is very straightforward, but if you use param groups it may be a little more involved. To determine the names of the layers the next commands are useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\nconv1.weight\nconv1.bias\nconv2.weight\nconv2.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfc3.weight\nfc3.bias\ntensor([[[[ 0.1539,  0.0896,  0.0490, -0.1535,  0.0020],\n          [ 0.0309, -0.1750,  0.0868, -0.1527, -0.0524],\n          [-0.1320, -0.1024,  0.0271, -0.1880, -0.1861],\n          [-0.1242,  0.0839, -0.1913,  0.1370,  0.1899],\n          [ 0.0739, -0.1770, -0.1475,  0.0048, -0.1703]]],\n\n\n        [[[ 0.1676,  0.1166,  0.1534, -0.1749,  0.0259],\n          [-0.0847,  0.0412, -0.1052,  0.0255, -0.0765],\n          [-0.0072, -0.0668, -0.0168, -0.0974,  0.0535],\n          [ 0.0466,  0.1062,  0.0685,  0.0344,  0.0292],\n          [-0.0633, -0.1403,  0.1636, -0.1849, -0.1479]]],\n\n\n        [[[ 0.0845,  0.0621,  0.1356, -0.1767, -0.1707],\n          [-0.1499,  0.0968, -0.0890,  0.0065,  0.0015],\n          [ 0.1017, -0.0010, -0.0732, -0.1482,  0.1475],\n          [-0.1158,  0.1767,  0.0100,  0.1703, -0.0020],\n          [-0.1782, -0.0926, -0.0813,  0.0400,  0.0070]]],\n\n\n        [[[ 0.1217, -0.1983,  0.1840,  0.0219,  0.1203],\n          [-0.1175,  0.1850,  0.0765, -0.1082, -0.1909],\n          [ 0.1705,  0.0483, -0.1880,  0.1324,  0.0672],\n          [-0.1472,  0.0643,  0.0551,  0.1725, -0.0772],\n          [ 0.0642, -0.1890,  0.0074,  0.0906, -0.1870]]],\n\n\n        [[[-0.0144, -0.1863,  0.0041, -0.0734, -0.0113],\n          [ 0.1117,  0.0724, -0.0280, -0.1593, -0.1956],\n          [-0.0239,  0.1933, -0.1398,  0.1708,  0.1146],\n          [-0.0702, -0.1581,  0.0839,  0.1700, -0.1461],\n          [-0.0449, -0.1765, -0.1755,  0.1146, -0.0205]]],\n\n\n        [[[-0.0257, -0.0173,  0.1636,  0.1686,  0.1353],\n          [ 0.0735, -0.0166,  0.0518,  0.0487, -0.1305],\n          [ 0.0805, -0.1451, -0.1688,  0.1553,  0.0832],\n          [-0.1906, -0.0629, -0.0977, -0.0849,  0.0804],\n          [ 0.1186,  0.0771,  0.0833, -0.1357, -0.0735]]]])\ntorch.Size([6, 1, 5, 5])\n"
    }
   ],
   "source": [
    "# The most useful, just print the network\n",
    "print(pytorch_network)\n",
    "\n",
    "# Also useful: will only print those layers with params\n",
    "state_dict = pytorch_network.state_dict()\n",
    "print(util.state_dict_layer_names(state_dict))\n",
    "for k,v in state_dict.items():\n",
    "    print(k)\n",
    "print(state_dict['conv1.weight'])\n",
    "print(state_dict['conv1.weight'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Define an equivalent Keras network. Use the built-in `name` keyword argument for each layer with params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<__main__.LeNet object at 0x13102aef0>\nconv1.weight\nconv1.bias\nconv2.weight\nconv2.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfc3.weight\nfc3.bias\nname conv2d_0.w_0, dtype: VarType.FP32 shape: [6, 1, 5, 5] \tlod: {}\n\tdim: 6, 1, 5, 5\n\tlayout: NCHW\n\tdtype: float\n\tdata: [0.0269396 0.570315 -0.395852 -0.159138 -0.123513 0.258803 -0.302941 -0.329502 0.00120546 0.185934 0.126938 0.0954494 -0.222355 0.211731 -0.384386 0.190065 0.0127135 0.250071 -0.304662 0.408702 0.144936 -0.201661 0.0899215 -0.0250759 0.00422118 -0.302021 -0.198132 -0.51248 0.124092 -0.163991 0.23053 -0.124536 0.0593972 -0.18371 0.405645 -0.0314066 -0.201687 0.223069 0.355114 -0.106769 0.156184 -0.444167 -0.0635065 -0.364388 -0.301678 -0.0326005 0.348064 -0.167422 0.134496 0.208305 0.711069 0.272064 -0.479625 0.087672 -0.216643 0.12084 0.347996 0.165636 -0.480425 0.300299 -0.275088 -0.199513 0.246383 -0.0783111 0.112633 -0.219666 0.156988 -0.197156 0.209432 0.382418 -0.161711 -0.174804 0.358004 -0.320728 0.526463 -0.232346 -0.0840232 0.140669 0.209521 0.574655 -0.35688 0.0759158 -0.374461 -0.0473881 -0.248869 -0.0220139 -0.535661 -0.453329 0.24399 0.474971 0.245928 -0.374947 -0.440421 0.0675676 0.00230617 -0.0843003 -0.471352 -0.235788 0.338752 -0.130042 -0.324871 0.366046 0.271726 0.021631 0.128077 0.0766889 -0.156788 0.282011 0.0168395 0.46049 0.108991 -0.597741 0.239149 0.207829 -0.341261 0.241689 0.257954 -0.184372 0.297804 -0.204683 -0.546885 -0.0538454 -0.280081 0.0118855 0.170265 -0.028482 0.00884399 -0.187961 0.0052665 0.445705 0.383793 0.165116 -0.0560171 0.390746 0.123535 0.156189 -0.215862 -0.217066 -0.524266 0.520784 0.348517 -0.571977 0.248306 -0.173463 0.178141 -0.124729 -0.373309 0.210445 -0.457923 -0.0267629]\n\n"
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear, Conv2DTranspose\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "# K.set_image_data_format('channels_first')\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=1, num_filters=6, filter_size=5, act='relu')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='relu')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.fc1 = Linear(input_dim=16*5*5, output_dim=120, act='relu')\n",
    "        self.fc2 = Linear(input_dim=120, output_dim=84, act='relu')\n",
    "        self.fc3 = Linear(input_dim=84, output_dim=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    paddle_network = LeNet()\n",
    "    print(paddle_network)\n",
    "    state_dict = paddle_network.state_dict()\n",
    "    # print(util.state_dict_layer_names(state_dict))\n",
    "    for k, v in state_dict.items():\n",
    "        print(k)\n",
    "    print(state_dict['conv1.weight'])\n",
    "    # state_dict.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_qat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4\n",
    "Now simply convert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Layer names in PyTorch state_dict ['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\nLayer names in paddle state_dict ['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\nniubi <_io.TextIOWrapper name='save_temp.pdparams' mode='a' encoding='UTF-8'>\nniubi <_io.TextIOWrapper name='save_temp.pdparams' mode='a' encoding='UTF-8'>\nniubi <_io.TextIOWrapper name='save_temp.pdparams' mode='a' encoding='UTF-8'>\nniubi <_io.TextIOWrapper name='save_temp.pdparams' mode='a' encoding='UTF-8'>\nniubi <_io.TextIOWrapper name='save_temp.pdparams' mode='a' encoding='UTF-8'>\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Parameter not found, Can't not find [ conv1.weight ] in stat_dictuse_structured_name is set to [True]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e73aeb1d6735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transfer.pytorch_to_paddle(keras_network, pytorch_network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp2f_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_to_paddle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddle_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/pytorch2paddle_nn/Joe_PyTorch2Paddle_fluid/Joe_nn_transfer/p2f_trans.py\u001b[0m in \u001b[0;36mpytorch_to_paddle\u001b[0;34m(pytorch_model, paddle_model, flip_filters, flip_channels, verbose)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# pytorch_model.load_state_dict(state_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdygraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mpaddle_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'save_temp.pdparams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mset_dict\u001b[0;34m(self, stat_dict, include_sublayers, use_structured_name)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mstat_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0minclude_sublayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_sublayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             use_structured_name=use_structured_name)\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     def load_dict(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mload_dict\u001b[0;34m(self, stat_dict, include_sublayers, use_structured_name)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"Parameter not found, Can't not find [ {} ] in stat_dict\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \"use_structured_name is set to [{}]\".format(\n\u001b[0;32m--> 547\u001b[0;31m                         key_name, use_structured_name))\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0munused_para_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstat_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parameter not found, Can't not find [ conv1.weight ] in stat_dictuse_structured_name is set to [True]"
     ]
    }
   ],
   "source": [
    "# transfer.pytorch_to_paddle(keras_network, pytorch_network)\n",
    "p2f_trans.pytorch_to_paddle(pytorch_network, paddle_network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Done!\n",
    "\n",
    "Now let's check whether it was succesful. If it was, both networks should have the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummy data\n",
    "# data = torch.rand(6,1,32,32)\n",
    "# data_keras = data.numpy()\n",
    "# data_pytorch = Variable(data, requires_grad=False)\n",
    "\n",
    "# # Do a forward pass in both frameworks\n",
    "# keras_pred = keras_network.predict(data_keras)\n",
    "# pytorch_pred = pytorch_network(data_pytorch).data.numpy()\n",
    "\n",
    "# Create dummy data\n",
    "data = torch.rand(6,1,32,32)\n",
    "data_paddle = data.numpy()\n",
    "data_pytorch = Variable(data, requires_grad=False)\n",
    "\n",
    "# Do a forward pass in both frameworks\n",
    "paddle_pred = paddle_network(data_paddle)\n",
    "pytorch_pred = pytorch_network(data_pytorch).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert keras_pred.shape == pytorch_pred.shape\n",
    "\n",
    "# plt.axis('Off')\n",
    "# plt.imshow(keras_pred)\n",
    "# plt.show()\n",
    "# plt.axis('Off')\n",
    "# plt.imshow(pytorch_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "They are the same, it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}