{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from Joe_nn_transfer import transfer, util, p2f_trans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Simply define your PyTorch model like usual, and create an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "pytorch_network = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Determine the names of the layers.\n",
    "\n",
    "For the above model example it is very straightforward, but if you use param groups it may be a little more involved. To determine the names of the layers the next commands are useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\nconv1.weight\nconv1.bias\nconv2.weight\nconv2.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfc3.weight\nfc3.bias\ntensor([[[[ 0.0707, -0.0501,  0.0964, -0.1343,  0.1532],\n          [-0.0278,  0.0048, -0.1483, -0.1993, -0.0422],\n          [-0.1017, -0.0814,  0.1391,  0.1890, -0.1501],\n          [-0.0538, -0.0041, -0.0746,  0.1505,  0.1568],\n          [-0.1743,  0.0445,  0.0212, -0.0575, -0.1678]]],\n\n\n        [[[-0.1156, -0.1424,  0.1084,  0.1871,  0.1440],\n          [ 0.0989,  0.0634, -0.0953, -0.1825,  0.0041],\n          [-0.0897,  0.1815, -0.0961, -0.0455,  0.1424],\n          [-0.1721, -0.0341, -0.1097, -0.0370, -0.1893],\n          [-0.0813, -0.0746, -0.1633,  0.0191, -0.0736]]],\n\n\n        [[[ 0.1749, -0.0139,  0.0774,  0.0920, -0.1023],\n          [-0.0425, -0.1093,  0.0925,  0.0325,  0.1925],\n          [ 0.0583, -0.0344,  0.0898, -0.1747, -0.1511],\n          [ 0.0706, -0.1813, -0.0826,  0.1203,  0.0325],\n          [ 0.1052, -0.0243,  0.0605,  0.0325,  0.0734]]],\n\n\n        [[[-0.1779,  0.1909,  0.1518,  0.1651,  0.1537],\n          [ 0.1739, -0.0190, -0.1156, -0.1486,  0.1128],\n          [-0.1340, -0.1552, -0.0544,  0.0663, -0.1293],\n          [-0.1067,  0.0422,  0.0923,  0.0811,  0.0241],\n          [ 0.0271,  0.1176, -0.0657, -0.1068, -0.1114]]],\n\n\n        [[[-0.0978, -0.1082, -0.0489,  0.0966,  0.1959],\n          [-0.0739, -0.1506,  0.0236, -0.0981, -0.1739],\n          [-0.1092,  0.1662,  0.0033, -0.0253, -0.1256],\n          [-0.1341,  0.0469, -0.0256,  0.1322, -0.0712],\n          [ 0.0785,  0.0806,  0.1087, -0.1632, -0.0650]]],\n\n\n        [[[ 0.1668,  0.0939, -0.1233, -0.1646, -0.1273],\n          [-0.0977,  0.0301,  0.1199, -0.1184, -0.1733],\n          [ 0.1121,  0.0380, -0.1217, -0.1094,  0.1805],\n          [-0.0325,  0.0077,  0.1153, -0.0908,  0.1769],\n          [ 0.1114, -0.1035,  0.0494,  0.1796,  0.1990]]]])\ntorch.Size([6, 1, 5, 5])\n"
    }
   ],
   "source": [
    "# The most useful, just print the network\n",
    "print(pytorch_network)\n",
    "\n",
    "# Also useful: will only print those layers with params\n",
    "state_dict = pytorch_network.state_dict()\n",
    "print(util.state_dict_layer_names(state_dict))\n",
    "for k,v in state_dict.items():\n",
    "    print(k)\n",
    "print(state_dict['conv1.weight'])\n",
    "print(state_dict['conv1.weight'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Define an equivalent Keras network. Use the built-in `name` keyword argument for each layer with params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<__main__.LeNet object at 0x109b5af50>\nconv1.weight\nconv1.bias\nconv2.weight\nconv2.bias\nfc1.weight\nfc1.bias\nfc2.weight\nfc2.bias\nfc3.weight\nfc3.bias\nname conv2d_0.w_0, dtype: VarType.FP32 shape: [6, 1, 5, 5] \tlod: {}\n\tdim: 6, 1, 5, 5\n\tlayout: NCHW\n\tdtype: float\n\tdata: [-0.0195192 0.166801 0.0483513 0.297938 0.00955139 0.0229684 0.533133 0.410709 -0.584196 0.279063 0.244781 0.143331 0.434516 0.115924 -0.0594141 -0.180877 0.307854 0.102176 0.118056 -0.300637 0.37904 -0.10797 -0.147727 -0.112089 0.455957 0.522227 -0.198681 -0.41545 -0.358607 -0.424032 0.517354 0.120713 0.104666 -0.133958 -0.0628879 -0.0890392 -0.162785 -0.00167088 -0.0315742 0.340461 0.165832 0.0689681 0.0988597 0.0272247 -0.352552 0.536348 0.244403 0.0930358 0.280713 0.239592 0.203817 -0.259892 0.365353 -0.228202 0.317915 -0.254233 -0.0914817 0.207284 -0.103901 -0.567613 0.215304 0.144952 0.190905 0.317872 0.0634739 -0.0791167 -0.0649471 0.382461 0.0510031 -0.0663796 0.0116494 -0.0778461 0.00144824 -0.425225 0.413482 0.212242 0.0537329 -0.00930037 -0.502016 -0.0727103 -0.25183 0.352246 0.404014 -0.549462 -0.00287801 -0.107102 0.0737985 0.0698824 -0.633274 0.367843 0.493448 0.0675091 -0.00280444 -0.0662724 0.0961762 0.0781725 0.326661 -0.0212243 0.0809657 -0.0378266 -0.204892 -0.296553 0.331208 -0.165791 0.315158 0.399705 0.1429 0.22138 -0.127327 -0.22793 -0.41042 -0.285661 0.215019 -0.0879796 -0.174882 -0.0685039 -0.205624 -0.391717 0.0234201 -0.00544135 -0.373088 -0.268806 -0.0866598 -0.0498916 0.317865 0.113041 -0.0788158 -0.0506971 -0.0976106 0.0521356 -0.0189755 -0.230497 0.4734 0.426061 0.0634708 -0.255019 -0.081643 -0.0198863 -0.393372 -0.306439 -0.367316 -0.131991 -0.315161 -0.166778 0.0146186 0.0614742 -0.0367013 -0.0203655 -0.35007 -0.0346586]\n\n"
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear, Conv2DTranspose\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "# K.set_image_data_format('channels_first')\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=1, num_filters=6, filter_size=5, act='relu')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='relu')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.fc1 = Linear(input_dim=16*5*5, output_dim=120, act='relu')\n",
    "        self.fc2 = Linear(input_dim=120, output_dim=84, act='relu')\n",
    "        self.fc3 = Linear(input_dim=84, output_dim=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    paddle_network = LeNet()\n",
    "    print(paddle_network)\n",
    "    state_dict = paddle_network.state_dict()\n",
    "    # print(util.state_dict_layer_names(state_dict))\n",
    "    for k, v in state_dict.items():\n",
    "        print(k)\n",
    "    print(state_dict['conv1.weight'])\n",
    "    # state_dict.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_qat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4\n",
    "Now simply convert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Layer names in PyTorch state_dict ['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\nLayer names in paddle state_dict ['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'LeNet' object has no attribute 'load_weights'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e73aeb1d6735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# transfer.pytorch_to_paddle(keras_network, pytorch_network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp2f_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_to_paddle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddle_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/pytorch2paddle_nn/Joe_PyTorch2Paddle_fluid/Joe_nn_transfer/p2f_trans.py\u001b[0m in \u001b[0;36mpytorch_to_paddle\u001b[0;34m(pytorch_model, paddle_model, flip_filters, flip_channels, verbose)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mpaddle_h5_layer_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPADDLE_MOVING_VARIANCE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# pytorch_model.load_state_dict(state_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdygraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LeNet' object has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "# transfer.pytorch_to_paddle(keras_network, pytorch_network)\n",
    "p2f_trans.pytorch_to_paddle(pytorch_network, paddle_network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Done!\n",
    "\n",
    "Now let's check whether it was succesful. If it was, both networks should have the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dummy data\n",
    "# data = torch.rand(6,1,32,32)\n",
    "# data_keras = data.numpy()\n",
    "# data_pytorch = Variable(data, requires_grad=False)\n",
    "\n",
    "# # Do a forward pass in both frameworks\n",
    "# keras_pred = keras_network.predict(data_keras)\n",
    "# pytorch_pred = pytorch_network(data_pytorch).data.numpy()\n",
    "\n",
    "# Create dummy data\n",
    "data = torch.rand(6,1,32,32)\n",
    "data_paddle = data.numpy()\n",
    "data_pytorch = Variable(data, requires_grad=False)\n",
    "\n",
    "# Do a forward pass in both frameworks\n",
    "paddle_pred = paddle_network(data_paddle)\n",
    "pytorch_pred = pytorch_network(data_pytorch).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert keras_pred.shape == pytorch_pred.shape\n",
    "\n",
    "# plt.axis('Off')\n",
    "# plt.imshow(keras_pred)\n",
    "# plt.show()\n",
    "# plt.axis('Off')\n",
    "# plt.imshow(pytorch_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "They are the same, it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}